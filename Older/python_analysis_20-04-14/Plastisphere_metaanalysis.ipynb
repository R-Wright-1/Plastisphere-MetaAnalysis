{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details to recreate the Plastisphere meta-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook that can be used to recreate all of the analyses found in the Plastisphere meta-analysis paper, or alternatively to re-do these analyses while also incorporating additional data.\n",
    "Before running, you should check that:\n",
    "- PICRUSt2 is installed and the environment is assumed to be called picrust2 (https://github.com/picrust/picrust2/wiki)\n",
    "- R is installed (https://www.r-project.org/)\n",
    "- You have downloaded all of the documents from https://doi.org/10.6084/m9.figshare.12227303:\n",
    "    - *This contains all of the files produced during this analyses*\n",
    "    - *If you wish to recreate the analyses, then take only the 'recreate_analyses' folder - the 'paper_data_20-04-14' may be used to compare your output with if you wish'*\n",
    "    - *If you are also using your own data, then replace what is inside the qiime_output folder with your own data*\n",
    "- You have installed the following Python packages: \n",
    "    - Bio (https://biopython.org/)\n",
    "    - cartopy (https://scitools.org.uk/cartopy/docs/latest/)\n",
    "    - pandas (https://pandas.pydata.org/)\n",
    "    - scipy (https://www.scipy.org/)\n",
    "    - scikit-bio (http://scikit-bio.org/)\n",
    "    - scikit-learn (https://scikit-learn.org/stable/)\n",
    " - And the following R packages:\n",
    "    - ggplot2 (https://ggplot2.tidyverse.org/)\n",
    "    - phyloseq (https://joey711.github.io/phyloseq/)\n",
    "    - ape (https://cran.r-project.org/web/packages/ape/ape.pdf)\n",
    "    - microbiome (https://microbiome.github.io/tutorials/)\n",
    "    - metacoder (https://grunwaldlab.github.io/metacoder_documentation/)\n",
    "    - ggtree (https://guangchuangyu.github.io/software/ggtree/)\n",
    "    - ggnewscale (https://github.com/eliocamp/ggnewscale)\n",
    "\n",
    "It is expected that there are several other files in the directory that contains this notebook:\n",
    "- agglomerate_and_unifrac.R\n",
    "- all_functions_new.py\n",
    "- metacoder.R\n",
    "- metadata.txt\n",
    "- plot_ancom_tree_heatmap.R\n",
    "- Study_dates.csv\n",
    "- Study_location.csv\n",
    "- unifrac_grouped_samples.R\n",
    "- world_map.jpg\n",
    "\n",
    "In the folder 'recreate_analyses' you should have the following file setup (essential whether you are adding your own data or repeating the analyses in the paper) - this should be how it comes if you have downloaded from the above Figshare link:\n",
    "- picrust\n",
    "    - kegg_list.csv\n",
    "    - ko_all.txt\n",
    "- qiime_output\n",
    "    - dna-sequences.fasta\n",
    "    - feature-table_w_tax.txt\n",
    "    - tree.nwk\n",
    "\n",
    "If you want to save on computation time for recreating the analysis from the paper, then you can add the following folders/subfolders/files from the paper_data_20-04-14' folder (so as computationally intensive steps such as agglomeration and random forest construction are not carried out again):\n",
    "- agglom (4 files)\n",
    "    - otu_table.csv\n",
    "    - reduced_tree.tree\n",
    "    - unweighted_unifrac.csv\n",
    "    - weighted_unifrac.csv\n",
    "- random_forest  (7 files, 2 subfolders)\n",
    "    - leave_one_dataset_out (7 files)\n",
    "        - ASVs.csv\n",
    "        - classes.csv\n",
    "        - families.csv\n",
    "        - genera.csv\n",
    "        - orders.csv\n",
    "        - phyla.csv\n",
    "        - species.csv\n",
    "    - single_environment (32 files)\n",
    "        - aquatic.csv\n",
    "        - freshwater.csv\n",
    "        - marine.csv\n",
    "        - terrestrial.csv\n",
    "        The following for each of 'aquatic', 'freshwater', 'marine' and 'terrestrial', where the name in inverted commas replaces 'environment':\n",
    "        - environment_ASVs.csv\n",
    "        - environment_classes.csv\n",
    "        - environment_families.csv\n",
    "        - environment_genera.csv\n",
    "        - environment_orders.csv\n",
    "        - environment_phyla.csv\n",
    "        - environment_species.csv\n",
    "    - ASVs_overall.csv\n",
    "    - classes_overall.csv\n",
    "    - families_overall.csv\n",
    "    - genera_overall.csv\n",
    "    - orders_overall.csv\n",
    "    - phyla_overall.csv\n",
    "    - species_overall.csv\n",
    "- picrust (4 files, 1 subfolder)\n",
    "    - feature_table_agglom.txt\n",
    "    - kegg_list.csv\n",
    "    - ko_all.txt\n",
    "    - sequences_agglom.fasta\n",
    "    - picrust_out (3 files, 2 subfolders - although we only actually need one of these files from one subfolder)\n",
    "        - ko_all_metagenome_out (4 files)\n",
    "            - pred_metagenome_unstrat.tsv.gz\n",
    "\n",
    "For any of the functions here, you can find out more information by using the doc strings, i.e. by typing print(function_name.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, import the functions and the other script that we will be using here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import all_functions_new as af\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set up the names and locations of some files, and make some empty folders:\n",
    "Note *You should change basedir to be wherever your folder is that contains picrust and qiime_output\n",
    "You should also change n_jobs to be the number of processors that you want to use (this will affect the speed with which many functions run)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/Users/robynwright/Documents/OneDrive/ACU_meta-analysis/Data_2020/paper_data_20-04-14/' \n",
    "ft_tax, meta_fn, seqs, study_locs, study_dates = basedir+'qiime_output/feature-table_w_tax.txt', 'metadata.txt', basedir+'qiime_output/dna-sequences.fasta', 'Study_location.csv', 'Study_dates.csv'\n",
    "n_jobs, est = 10, 1\n",
    "\n",
    "folder_names = [\"agglom\", \"picrust\", \"figures\", \"ancom\", \"figures/ancom\", \"figures/metacoder\", \"random_forest\", \"random_forest/single_environment\", \"random_forest/leave_one_dataset_out\", \"figures/random_forest\", \"figures/random_forest/single_environment\", \"figures/random_forest/leave_one_dataset_out\"]\n",
    "for fn in folder_names:\n",
    "    if not os.path.exists(basedir+\"/\"+fn):\n",
    "       os.system(\"mkdir \"+basedir+\"/\"+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now format the QIIME2 output files for running the R agglomeration and unifrac scripts\n",
    "Note *If you already have the R input and tax_dict made then to save time, you can just open the tax_dict*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(basedir+'tax_dict.dictionary'):\n",
    "    tax_dict = af.open_pickle(basedir+'tax_dict.dictionary')\n",
    "else:\n",
    "    ft, tax_dict = af.format_R(ft_tax, basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run the R script:\n",
    "Note *the location here may need changing if this doesn't work. You can type which Rscript into terminal to find out the output here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(basedir+'agglom/otu_table.csv'): #if we haven't already done this and got the agglomerated OTU table\n",
    "    os.rename(basedir+'feature_table.csv', 'feature_table.csv') #move the feature table to the right directory\n",
    "    os.rename(basedir+'qiime_output/tree.nwk', 'tree.nwk') #and the tree\n",
    "    \n",
    "    #Change the location of Rscript, if necessary\n",
    "    os.system(\"/usr/local/bin/Rscript agglomerate_and_unifrac.R\") #run the R script to agglomerate and calculate unifrac distances\n",
    "    \n",
    "    os.rename('feature_table.csv', basedir+'feature_table.csv') #now move the feature table back to where it came from\n",
    "    os.rename('tree.nwk', basedir+'qiime_output/tree.nwk') #and the tree\n",
    "    os.rename('otu_table.csv', basedir+'agglom/otu_table.csv') #move the OTU table to the right directory\n",
    "    os.rename('reduced_tree.tree', basedir+'agglom/reduced_tree.tree') #and the tree\n",
    "    os.rename('weighted_unifrac.csv', basedir+'agglom/weighted_unifrac.csv') #and the weighted unifrac distance matrix\n",
    "    os.rename('unweighted_unifrac.csv', basedir+'agglom/unweighted_unifrac.csv') #and the unweighted unifrac distance matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Now we can read in these new files and open the information that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df, tree_agglom = af.open_and_sort(basedir+'/agglom/otu_table.csv'), basedir+'/agglom/reduced_tree.tree'\n",
    "w_uf, uw_uf = af.open_and_sort(basedir+'agglom/weighted_unifrac.csv'), af.open_and_sort(basedir+ 'agglom/unweighted_unifrac.csv') #file names for unifrac distances based on agglomerated data\n",
    "meta, meta_names, meta_dict = af.get_meta(meta_fn)\n",
    "meta_df = af.get_meta_df(meta, meta_names, list(ft_df.columns))\n",
    "ft_full = basedir+'feature_table.csv'\n",
    "\n",
    "if os.path.exists(basedir+'ASV_dict.dictionary'):\n",
    "    ASV_dict = af.open_pickle(basedir+'ASV_dict.dictionary')\n",
    "else:\n",
    "    ASV_dict = af.get_ASV_dict(ft_df, basedir+seqs)\n",
    "    af.write_pickle(basedir+'ASV_dict.dictionary', ASV_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. PICRUSt (only run if we don't have this already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(basedir+'picrust/picrust_out/ko_all_metagenome_out/pred_metagenome_unstrat.tsv.gz'):\n",
    "    seqs_agglom_fn, ft_agglom_fn = af.filter_seqs(ft_df, seqs) \n",
    "    os.system(\"source activate picrust2\") \n",
    "    os.system(\"picrust2_pipeline.py -s \"+seqs_agglom_fn+\" -i \"+ft_agglom_fn+\" -o picrust/picrust_out --custom_trait_tables ko_all.txt --stratified --no_pathways\") \n",
    "if not os.path.exists(basedir+'KO_dict.dictionary'):\n",
    "    ko_file = basedir+'picrust/kegg_list.csv' \n",
    "    KO_dict, KO_dict_full = af.make_KO_dict(ko_file) \n",
    "else:\n",
    "    KO_dict = af.open_pickle(basedir+'KO_dict.dictionary') \n",
    "if not os.path.exists(basedir+'picrust.dataframe'):\n",
    "    picrust_file = 'picrust/picrust_out/ko_all_metagenome_out/pred_metagenome_unstrat.tsv.gz' \n",
    "    picrust = pd.read_csv(basedir+'/'+picrust_file, sep='\\t', header=0, index_col=0) \n",
    "    picrust, KO_dict = af.filter_picrust(basedir+picrust_file, KO_dict, KO_dict_full) \n",
    "else:\n",
    "    picrust = af.open_pickle(basedir+'picrust.dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to do all of the analysis and make all of the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Get basic study map and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.study_map(study_dates, study_locs, basedir) \n",
    "af.study_metrics(meta_df, basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Get the similarity heatmap and nMDS plots using the weighted and unweighted unifrac distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robynwright/Documents/OneDrive/Github/Plastisphere-MetaAnalysis/python_analysis_20-04-14/all_functions_new.py:824: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if npos == '':\n",
      "/Users/robynwright/Documents/OneDrive/Github/Plastisphere-MetaAnalysis/python_analysis_20-04-14/all_functions_new.py:824: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if npos == '':\n"
     ]
    }
   ],
   "source": [
    "w_uf.to_csv(basedir+'agglom/sorted_weighted_unifrac.csv')\n",
    "uw_uf.to_csv(basedir+'agglom/sorted_unweighted_unifrac.csv')\n",
    "af.nmds_plot_study_env('agglom/sorted_weighted_unifrac.csv', 'agglom/sorted_unweighted_unifrac.csv', meta_dict, basedir) \n",
    "af.similarity_heatmap_combined(w_uf, uw_uf, basedir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Get the figure that summarises the sample types, groups them to a dendrogram, gets stacked bar plots at phyla level, heatmap of families, simpsons diversity and venn diagram of ASVs shared between sample types in different environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:961: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    }
   ],
   "source": [
    "af.bar_dendro_venn(ft_df, ft_full, meta_dict, basedir, tax_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Get Ancom trees and heatmaps for early and late incubation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[af.tree_heatmap(ft_df, meta_dict, basedir, tax_dict, level=al) for al in [1, 2, 3, 4, 5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Get the metacoder plots for early and late incubation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.metacoder(ft_df, tax_dict, meta_dict, basedir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Get the overall random forests (skip this if you downloaded the files of the already constructed random forests)\n",
    "*Note that if you re-run this section then you might get slightly different results than the paper due to different random selections of 20%/80% of the data for testing/training)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.get_random_forests(ft_df, tax_dict, meta_df, basedir, est=est, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Now check how the accuracy of our models goes down when we leave out individual studies (skip this if you downloaded the files of the already constructed random forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.get_random_forests_leave_one_dataset_out(ft_df, tax_dict, meta_df, basedir, meta_dict, est=10000, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Get the random forests for each environment for general plastic type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.get_environment_random_forest(ft_df, tax_dict, meta_df, meta_dict, basedir, est=10000, n_jobs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. And get the random forest figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Thermotogae'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1cb201c783e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#af.get_random_forest_plots(ft_df, tax_dict, ASV_dict, meta_dict, basedir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#af.leave_one_out_plots(basedir, meta_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overall_random_forest_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASV_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/OneDrive/Github/Plastisphere-MetaAnalysis/python_analysis_20-04-14/all_functions_new.py\u001b[0m in \u001b[0;36mget_overall_random_forest_plot\u001b[0;34m(ft, meta_df, tax_dict, ASV_dict, meta_dict, basedir)\u001b[0m\n\u001b[1;32m   2442\u001b[0m     '''\n\u001b[1;32m   2443\u001b[0m     \u001b[0mmetadata_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_forest_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASV_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_individual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m     \u001b[0menv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_environment_random_forest_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASV_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m     \u001b[0menv_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m     \u001b[0menv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive/Github/Plastisphere-MetaAnalysis/python_analysis_20-04-14/all_functions_new.py\u001b[0m in \u001b[0;36mget_environment_random_forest_plots\u001b[0;34m(ft, meta_df, tax_dict, ASV_dict, meta_dict, basedir)\u001b[0m\n\u001b[1;32m   2423\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2425\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_forest_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASV_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_individual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2426\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Plastic type (general)'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive/Github/Plastisphere-MetaAnalysis/python_analysis_20-04-14/all_functions_new.py\u001b[0m in \u001b[0;36mget_random_forest_plots\u001b[0;34m(ft, tax_dict, ASV_dict, meta_dict, basedir, other_folder, skip_individual)\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m             \u001b[0mdf_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Alteromonas macleodii'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Marinimicrobia (SAR406 clade)'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m             \u001b[0mdf_rf_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_by_tax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m             \u001b[0mdf_rf_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_by_tax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtax_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive/Github/Plastisphere-MetaAnalysis/python_analysis_20-04-14/all_functions_new.py\u001b[0m in \u001b[0;36msort_by_tax\u001b[0;34m(df, level, other_levels, tax_dict, names)\u001b[0m\n\u001b[1;32m   1849\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m                 \u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m             \u001b[0mnew_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mother_levels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#append the appropriate value for the current higher level as well as the current taxon name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtax_dict\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#if tax_dict isn't False (i.e. if we are looking at the level of ASV - we use tax_dict as here we already worked out the lowest classification for each ASV)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtax_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_tax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#get the lowest classification for each ASV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Thermotogae'"
     ]
    }
   ],
   "source": [
    "#af.get_random_forest_plots(ft_df, tax_dict, ASV_dict, meta_dict, basedir)\n",
    "#af.leave_one_out_plots(basedir, meta_df)\n",
    "af.get_overall_random_forest_plot(ft_df, meta_df, tax_dict, ASV_dict, meta_dict, basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. And get the environment random forest figures for general plastic type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.get_environment_random_forest_plots(ft_df, meta_df, tax_dict, ASV_dict, meta_dict, basedir)\n",
    "af.make_env_rf_plot(ft_df, tax_dict, basedir, ASV_dict, meta_dict)\n",
    "af.make_env_rf_plot(ft_df, tax_dict, basedir, ASV_dict, meta_dict, mx=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Get the PICRUSt2 plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_dict = af.open_pickle(KO_dict) #load the picrust kegg ortholog dictionary \n",
    "picrust = af.open_pickle(picrust) #and the picrust data\n",
    "af.picrust_plots(picrust, KO_dict, meta_dict, basedir) #now make the picrust volcano and bar plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. And get the separate plots for each study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.plots_per_study(ft_df, meta_df, meta_dict, w_uf, uw_uf, tax_dict, ASV_dict, basedir, est=est, n_jobs=n_jobs) #get the plots summarising the results per study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. And check how long everything took to run (if desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running time was', datetime.now()-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
